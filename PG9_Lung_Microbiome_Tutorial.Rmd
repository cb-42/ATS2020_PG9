---
title: "PG9_Lung_Microbiome_Tutorial"
author: "Christopher Brown"
date: "February 11, 2020 (updated)"
output: html_document
---
This report was built with R version `r getRversion()`. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# I. Introduction
Welcome. [introduction goes here - reminder to download RStudio/necessary packages if attendees haven't already done so]  

## 1.1 Why RStudio?
There are many quality of life features that aid in making your time spent coding more efficient and reproducible. Many keyboard shortcuts exist in RStudio for common tasks. Navigate to Help > Keyboard Shortcuts Help, for a full list.  

## 1.2 Why RMarkdown?  
  - Easily combine narrative, code, statistics, and visualizations.  
  - Reproducibility  
  - Generate high quality reports in a variety of formats: pdf, html, slides... etc  

## 1.3 Navigating RStudio & an RMarkdown script  
RMarkdown documents consist of narrative of text such as this and code chunks such as the one below. Code chunks are enclosed within two pairs of three backticks (for reference a backtick is denoted by `).  

```{r example_code_chunk}
# This is an example of a comment within a code chunk. The # symbol means that any text following it should not be treated as R code.
# When R code is run in a code chunk it will be displayed inline - that is, within the document - just below the current code chunk.
# The next line is R code, and it will be executed when this code chunk is run. Run with: green arrow in uppe right of this section, cmd + enter (mac), ctrl + enter (pc).
paste("Welcome to ATS 2020, PG9", "-", "A Hands-On Introduction to Studying the Lung Microbiome")
```

## 1.4 Library Load  
Before we begin bringing in the data to begin our analysis, we need to load the libraries that we'll use. Libraries contain additional code (primarily functions) and/or data that expand R's base functionality. A good practice is to keep a code chunk near the top of your script that contains all the libraries that are utilized in the analysis, so it's easy to keep track of all of the dependencies that your code has.

```{r libraries, message = FALSE}
# This section contains typical libraries used in these analyses

# I. universal data wrangling and visualization
library(tidyverse)      # ggplot, dplyr, purrr, forcats, stringr... and other packages. See https://tidyverse.tidyverse.org/

# II. machine learning & analysis packages
library(vegan)          # decostand(), metaMDS(), scores(), rda(), ordispider(), adonis()
library(mvabund)        # mvabund(), manyglm()
library(randomForest)   # randomForest()

# III. formatting, plotting
library(scales)         # used in formatting relative abundance % labels; unit_format()
library(RColorBrewer)   # brewer.pal() for generating custom palettes
library(knitr)          # kable(), for displaying nicer tables in html/pdf output
```

## 1.5 Notes on R code syntax, best practices  
  - package_name::function_name()  
      - Main reason to do this is to avoid calling the wrong function of the same name, as we'll see with dplyr::select(). Also informs users what library a function is from. 
  - Give your objects meaningful, formulaic names (not always easy when you create dozens or hundreds of them)  
  - Include comments explaining what your code does (the primary beneficiary will likely be your future self)  
  - Become familiar with and make use of the pipe operator: `%>%`. This can drastically improve the efficiency of your time spent coding, and is a natural fit for data wrangling workflows.
  
# II. Data Preparation
We will be using 16S data resulting from mothur processing and metadata that was previously generated. All of this data is available [here](https://github.com/dicksonlunglab/mouse_lung_microbiome_variability/tree/master/mouse_lung_microbiome_heterogeneity).

```{r load_16S_rawdata}
# For ease of use, place the processed 16S data files of interest into the same directory as your current RStudio project
# Best practices: keep a separate project for each experiment or combination of experiments
# include a data folder within the project's directory to keep source files organized; also somewhat mitigates the risk of modifying them inadvertently

# I. Read in .shared (counts of sequences assigned to OTU #s)
# Includes basic processing with selection of OTUs > 0.1 % of the population
otu_raw <- read.table("data/Heterogeneity.shared.txt", row.names = 2, header = TRUE)
otu_trim <- otu_raw[, -c(1:2)]
otu_trim <- as.matrix(otu_trim)
otu_tmp <- vegan::decostand(otu_trim, "total") * 100
otu_trim[which(otu_tmp < 0.1)] <- 0
otu_good <- otu_trim[, which(colSums(otu_trim) > 0)]

# Trim _S from end of rownames(otu_good); note that it may be useful to keep these well identifiers in some analyses
rownames(otu_good) <- str_remove(rownames(otu_good), "_S\\d+")

# It's a good idea to inspect the data regularly with tools such as dim(), str(), head(), tail(), summary()... This will help in catching errors earlier
dim(otu_good) # dim(otu_good)[1] observations (samples) x dim(otu_good)[2] features (OTUs above .1% population threshold)
otu_good[1:20, 1:20] # use other means of showing a glimpse of the data?


# II. Read in cons.taxonomy (for each OTU: taxonomic levels down to Genus, if possible)
# Note that OTUs are in rows here rather than columns
# 2 imports are required due to the combination of 2 different separators  
tax1 <- read.table("data/Heterogeneity.0.03.cons.taxonomy.txt", sep = "\t", row.names = 1, header = TRUE, colClasses = c("character", "numeric", "character"))
tax2 <- read.table("data/Heterogeneity.0.03.cons.taxonomy.txt", sep = ";", skip = 1, col.names = c("", "Phylum", "Class", "Order", "Family", "Genus", "")) %>% 
  dplyr::select(-c(1, 7)) %>% 
  purrr::map_df(stringr::str_replace, "\\(.*.\\)", "") %>%
  purrr::map_df(as.factor)
otu_taxonomy <- data.frame(OTU = rownames(tax1), Size = tax1[, 1], tax2, stringsAsFactors = FALSE)
rownames(otu_taxonomy) <- rownames(tax1)

# trim otu_taxonomy based on OTUs in otu_good
otu_good_taxonomy <- otu_taxonomy[otu_taxonomy$OTU %in% colnames(otu_good), ]
rownames(otu_good_taxonomy) <- intersect(rownames(otu_taxonomy), colnames(otu_good))
otu_good_taxonomy <- as.data.frame(otu_good_taxonomy)

dim(otu_good_taxonomy)
otu_good_taxonomy[1:20,]
```

```{r metadata_wrangling, include = FALSE}
# Load in metadata/environmental data, or create it

## Load approach using metadat from github repo
meta_df <- read.table("data/Heterogeneity.metadata.txt", sep = "\t", header = TRUE) 
# Note that this will create factors out of all chr type columns
#While - undesirable for 'specimen' but useful for 'reagent_tissue', 'litter', 'vendor', 'mouse', 'tissue_type', and 'cage'
otu_df <- data.frame(meta_df, decostand(otu_good, "total") * 100)
otu_df$specimen <- as.character(otu_df$specimen) # let's convert 'specimen' back to a chr-type

# Examples of metadata creation using regular expressions (regex) in a tidyverse pipeline
# Note that extracting metadata from sample names is much easier if naming conventions are consistent in terms of spelling and placement
# otu_df <- data.frame(decostand(otu_good, "total") * 100, Sample_name = row.names(otu_good), stringsAsFactors = FALSE) %>%
#   # Create Specimen_ctrl from first string of characters prior to first "_"
#   mutate(Specimen_ctrl = factor(case_when(str_detect(Sample_name, "^AE_") ~ "AE",
#                                        str_detect(Sample_name, "^Blank\\d_") ~ "Empty",
#                                        str_detect(Sample_name, "^Heparin_") ~ "Heparin",
#                                        str_detect(Sample_name, "^HomogCtrl_") ~ "HomogCtrl",
#                                        str_detect(Sample_name, "^IsoCtrl_") ~ "IsoCtrl",
#                                        str_detect(Sample_name, "^LPS_") ~ "LPS",
#                                        str_detect(Sample_name, "^PerfusionPBS_") ~ "PBS",
#                                        str_detect(Sample_name, "^WATERD|^waterC") ~ "WaterNeg",
#                                        str_detect(Sample_name, "^mock[CD]") ~ "Mock",
#                                        str_detect(Sample_name, "^[:alnum:]+") ~ str_extract(Sample_name, "^[:alnum:]+")), # for experimental groups, place after other steps because this regex would fill in values for controls (may or may not be ideal)
#                                 levels = c("CR1", "CR2", "JAX1", "JAX2", "AE", "Empty", "Heparin", "HomogCtrl", "IsoCtrl", "LPS", "PBS", "WaterNeg", "Mock")
#                 )
#          ) %>%
#   # Create Organ
#   mutate(Organ = factor(case_when(str_detect(Sample_name, "_CECUM_") ~ "Cecum",
#                                   str_detect(Sample_name, "_LUNG_HOMOG") ~ "Lung",
#                                   str_detect(Sample_name, "_NASAL_") ~ "Nasal",
#                                   str_detect(Sample_name, "_TONGUE_") ~ "Tongue"),
#                         levels = c("Nasal", "Tongue", "Lung", "Cecum")
#                 ) # sum(is.na(otu_df$Organ)) returns 32 (as expected, controls have NA in this column)
#          ) %>%
#   # Create Mouse
#   mutate(Mouse = as.numeric(str_extract(Sample_name, "(?<=(CR\\d|JAX\\d)_)\\d+") # numbers correspond to mice if a CR or JAX specimen
#               ) # sum(is.na(otu_df$Mouse)) returns 32 (as expected, the controls have NA in this column)
#          ) %>%
#   # metadata columns at front, followed by all of the count data
#   dplyr::select(Sample_name:Mouse, everything())
#   # note that the data is in wide format
#   
# otu_df$Specimen_ctrl %>% table() %>% sum() # 192: all samples/rows are accounted for
# otu_df$Organ %>% summary() %>% sum() # ditto; 32 NAs for organs
```

We'll also go ahead and create a custom palette for use in some of our visualizations. Although we might not realize we need this until later in the analysis, it makes sense to include elements like this in the preparation part of your analysis. Apart from the organizational benefit, code that relies on the palette won't run if the palette hasn't been defined - so it is best to define the palette before creating any visualizations.  

```{r pal_prep, fig.width=8}
# for PCA ordinations; choose an 9 that covers the maximum number of factor levels (conditions) within a variable of interest
pcapal <- brewer.pal(9,"Set1")
```

# III. Comparing Community Composition

## 3.1 Visualization techniques

### 3.1.1 PCA Ordination  

[Descriptive text here]  

```{r pca_prep}
# Filter data to retain lung tissue only
otu_lung <- dplyr::filter(otu_df, tissue_type == "Lung") %>%
  droplevels() # remove levels that are no longer present due to filtering
rownames(otu_lung) <- otu_lung$specimen

# PCA of all data (non-control)
otu_lung_hel <- decostand(dplyr::select(otu_lung, contains("Otu")), "hellinger") # use OTU columns only
otu_lung_pca <- rda(otu_lung_hel)

# summary() produces a list which is rather messy to print out all at once. Let's just examine the importance of the principal components
summary(otu_lung_pca)$cont # 0.1458 0.10677 0.06776 proportion explained by first 3 axes

# Permanova
set.seed(8947) # setting a seed allows for reproducibility - both lines need to be run together
adonis(otu_lung_hel~otu_lung$vendor, method="euclidean", permutations = 10000) # 9.999e-05 ***
```

```{r spider_pca, fig.height=10, fig.width=10}
# This approach combines base R plotting functionality and vegan's ordispider function, which creates the lines connecting points to the centroids.
plot(otu_lung_pca, type = "n", font = 2, font.lab = 2, xlab = "PC1 (14.58% Explained)", ylab = "PC2 (10.68% Explained)", main = "PCA of Specimen Origin, colored by Vendor", display = "sites")
points(otu_lung_pca, pch = 19, col = pcapal[as.numeric(otu_lung$vendor)])
ordispider(otu_lung_pca, otu_lung$vendor, label = TRUE)
legend("topright", levels(otu_lung$vendor), pch = 19, col = pcapal, title = "Vendor")
legend("bottomright", legend = "Permanova: Difference between Specimen Origin: 9.999e-05") # Should signifiance test be include in the plot?
```

### 3.1.2 Trees and heat maps  

[Descriptive text here]  

```{r heatmap_prep}
# Determine the order of OTUs based on means within Lung specimens
otu_order <- names(sort(colMeans(otu_lung[, stringr::str_detect(colnames(otu_lung), "Otu")]), decreasing = TRUE))

heat_df <- otu_lung %>% 
  select(specimen, log_IL1a, otu_order[1:20]) %>%
  gather(key = OTU, value = Percentage, -log_IL1a, -specimen, factor_key = TRUE) #%>%
  # group_by(OTU) %>%
  # summarize(Mean_perc = mean(Percentage)) %>%
  # ungroup()
```

```{r ggheatmap, fig.height=8, fig.width=12}
# Note that the OTU levels are sorted in reverse order of abundance here - we could adjust this if desired.
ggplot(heat_df, aes(x = specimen, y = OTU)) +
  geom_tile(aes(fill = Percentage)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), plot.margin = unit(c(0.5,0.5,0.5,1),"cm")) +
  scale_fill_gradient(low = "white", high = "dark blue")
```

```{r dendro_heatmap, fig.height=8, fig.width=12}
# Unfortunately, filtering and other tidyverse functions strip rownames, but rownames are useful for pulling information out of matrices.
# Fortunately, there is a function to easily put the specimen column back into rownames
heat_df <- dplyr::filter(otu_df, tissue_type == "Lung") %>%
  droplevels() %>% 
  column_to_rownames("specimen") %>%
  select(otu_order[1:20])

# create Bray-Curtis matrix for specimens
bc_lung_spec <- vegdist(select(heat_df, otu_order[1:20]), method = "bray")
# The linkage method used will depend on the nature of the data
clust_lung_spec <- hclust(bc_lung_spec, method = "average")

# create Bray-Curtis matrix for OTUs
bc_lung_otu <- vegdist(t(select(heat_df, otu_order[1:20])), method = "bray")
clust_lung_otu <- hclust(bc_lung_otu, method = "average")

# Create the heatmap with dendrograms
heatmap(as.matrix(select(heat_df, str_which(colnames(heat_df), "Otu"))), Rowv = as.dendrogram(clust_lung_spec), Colv = as.dendrogram(clust_lung_otu), margins=c(5,0))
```

### 3.1.3 Rank abundance  
In the following series of examples, we'll use RA plots to compare the community composition in lung speciments against negative controls. Note that the strategies we'll use can be extended to conduct comparisons across any arbitrary groups, assuming metadata exists to identify the observations (rows) belonging to each group. For instance, we might compare four different types of tissue, or drill down into the controls and compare those subtypes.  

```{r prep_ra}
# First we need to prepare the data: controls in one group, lung tissue in another
# Order the data by most abundance OTU in lung tissue
# Include an errorbar
# Color by phyla

ra_df <- otu_df %>% # Note at this is just one of several possible approaches to filtering to retain the correct rows
  filter((reagent_tissue == "Control") | (tissue_type == "Lung")) %>% # 65 specimens
  droplevels() # remove factor levels with no remaining observations - saves potential headaches in downstream wrangling and visualizations

# Determine the order of OTUs based on means within Lung specimens
otu_order <- names(sort(colMeans(filter(ra_df, tissue_type == "Lung")[, str_detect(colnames(ra_df), "Otu")]), decreasing = TRUE))

# Keep top 20 OTUs, then reshape the dataframe from wide to long format
g_df <- ra_df %>%
  select(str_which(colnames(ra_df), "Otu", negate = TRUE), colnames(ra_df[, otu_order[1:20]])) %>% # Keep non-OTU columns, followed by the 20 most abundant OTU columns
  gather(key = OTU, value = Percentage, -str_which(colnames(ra_df), "Otu", negate = TRUE), factor_key = TRUE) # factor_key is important because we care about the order (clevels) in OTU
  
# Join Phylum column from taxonomy table
tax_df <- otu_good_taxonomy[otu_good_taxonomy[,"OTU"] %in% otu_order[1:20], c("OTU", "Phylum")] # Keep only the rows from ranked OTU vector, and OTU + whatever taxonomic level to use for filling bars
tax_df$OTU <- factor(tax_df$OTU, levels = otu_order[1:20]) # set OTU factor levels to be in the same order as in g_df. If this is not done, our OTU column will be coerced to a character vector when we join (we'll lose the levels)
g_df <- inner_join(g_df, tax_df, by = "OTU")

# dimensions have gone from 65 745 to 1300 17

# Generate mean and sem for each group
agg_df <- g_df %>%
  group_by(reagent_tissue, OTU, Phylum) %>%
  summarize(Mean_perc = mean(Percentage), SEM = sqrt(var(Percentage)/length(Percentage))) %>%
  ungroup()
```

```{r plot_ra_basic, fig.height=6, fig.width=12}
(p <- ggplot(agg_df, aes(x = OTU, y = Mean_perc, fill = reagent_tissue)) + 
  geom_col() +
  facet_grid(reagent_tissue ~ .))
```

Let's add an errorbar and improve the visual aesthetics.

```{r plot_ra_improved, fig.height=6, fig.width=12}
# Add an errorbar
(q <- p + geom_errorbar(aes(ymin = Mean_perc - SEM, ymax = Mean_perc + SEM, width = 0.3)))

# Clear background + modify theme (rotate x-axis labels, reposition legend)
(q <- q + theme_bw() + # note that a theme_ layer added after other other theme modifications will remove these prior modifications
    theme(panel.grid = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top"))
```

Adding Genus labels to Otu identifiers

```{r otu_lab, fig.height=6, fig.width=12}
# Add Genus levels to the OTU Number
levels(agg_df$OTU) <- fct_inorder(paste0(otu_good_taxonomy[levels(agg_df$OTU), ]$Genus, " (", levels(agg_df$OTU), ")"))
# equivalent to:
# cbmbtools::paste_tax(levels(agg_df$OTU))

ggplot(agg_df, aes(x = OTU, y = Mean_perc, fill = fct_rev(reagent_tissue))) + 
  geom_col() +
  facet_grid(fct_rev(reagent_tissue) ~ .) +
  geom_errorbar(aes(ymin = Mean_perc - SEM, ymax = Mean_perc + SEM, width = 0.3)) + 
  theme_bw() +
  theme(panel.grid = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top", plot.margin = unit(c(0.5,0.5,0.5,1),"cm")) + 
  scale_y_continuous(labels = unit_format(suffix = "%")) + 
  labs(title="Comparison of Lung Tissue and Controls", subtitle = "Ranked by lung tissue specimens", y = "% Relative Abundance")
```

How do we adjust the legend and facet labels?

```{r ra_factor, fig.height=6, fig.width=12}
# Although it is possible to adjust the values and labels within the ggplot workflow, perhaps the simplest approach would be to correct the reagent_tissue column values and factor levels prior to plotting
agg_df$reagent_tissue <- fct_recode(agg_df$reagent_tissue, Lung = "Tissue") %>%
  fct_relevel("Lung")

ggplot(agg_df, aes(x = OTU, y = Mean_perc, fill = reagent_tissue)) + 
  geom_col() + # use show.legend = FALSE to remove the legend entirely
  facet_grid(reagent_tissue ~ .) +
  geom_errorbar(aes(ymin = Mean_perc - SEM, ymax = Mean_perc + SEM, width = 0.3)) + 
  theme_bw() +
  theme(panel.grid = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top", plot.margin = unit(c(0.5,0.5,0.5,1),"cm"), legend.title = element_blank()) + 
  scale_y_continuous(labels = unit_format(suffix = "%")) + 
  labs(title="Comparison of Lung Tissue and Controls", subtitle = "Ranked by lung tissue specimens", y = "% Relative Abundance")
  # for further customizing of the legend, try adding a guide_legend() layer
```

How can we use fill color to show the phyla to which each OTU belongs?

```{r ra_phy_prep, fig.height=6, fig.width=12}
# First we need to prepare the taxonomic data - In this case we did this earlier in our overall RA data prep.

# Next, simply change the fill parameter to Phylum and rerun the ggplot code
ggplot(agg_df, aes(x = OTU, y = Mean_perc, fill = Phylum)) + 
  geom_col() + # use show.legend = FALSE to remove the legend entirely
  facet_grid(reagent_tissue ~ .) +
  geom_errorbar(aes(ymin = Mean_perc - SEM, ymax = Mean_perc + SEM, width = 0.3)) + 
  theme_bw() +
  theme(panel.grid = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top", plot.margin = unit(c(0.5,0.5,0.5,1),"cm"), legend.title = element_blank()) + 
  scale_y_continuous(labels = unit_format(suffix = "%")) + 
  labs(title="Comparison of Lung Tissue and Controls", subtitle = "Ranked by lung tissue specimens", y = "% Relative Abundance")

# Encourage participants to run these by commenting out a layer, altering 1 parameter to develop a deeper understanding of how to build up or alter a ggplot object
```


## 3.2 Hypothesis testing  

### 3.2.1 PERMANOVA (adonis)  
The following is an example of a permanova implementation using vegan::adonis().  

```{r adonis}
# This code was used previously when we prepared our PCA ordination
set.seed(8947) # setting a seed allows for reproducibility - both lines need to be run together
adonis(otu_lung_hel~otu_lung$vendor, method="euclidean", permutations = 10000) # 9.999e-05 ***
# The left hand side of the formula is the transformed data, and the right hand side is a vector (column) container the group identifiers of interest.
```

### 3.2.2 mvabund  
This may take some time to finish (about 4.5 minutes on a powerful machine), so while the model is running, we'll discuss some other topics. [additional explanation, topics here]. For code chunks that take a while to execute, whether due to statistical analyses or visualizations, it may be beneficial to set the code chunk cache parameter to TRUE. This will enable you to recreate your report much more quickly when making small changes elsewhere.

```{r mvabund, cache=TRUE}
a <- Sys.time() # Sometimes this can take a while, so it might be useful to keep track of the time with start/stop points to allow us to compute the duration.
otu_mva <- mvabund(otu_lung[,str_which(colnames(otu_lung), "Otu")]) # select only lung specimens and Otu columns
otu_ven_many <- manyglm(otu_mva ~ otu_lung$vendor)
otu_mva_results <- anova(otu_ven_many, p.uni="adjusted")
b <- Sys.time()
b - a

plot(otu_ven_many) # Residual plot
otu_mva_results$table # Signif

# Analysis of Deviance Table
# 
# Model: manyglm(formula = otu_mva ~ otu_lung$vendor)
# 
# Multivariate test:
#                 Res.Df Df.diff   Dev Pr(>Dev)    
# (Intercept)         39                           
# otu_lung$vendor     38       1 797.9    0.001 ***
# ---
# Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
```

### 3.2.3 constrained ordination  
Cage example using vegan. [descriptive text here]

```{r constrained}
# Run anova on our hellinger transformed data. We'll also need to pass in one or more vectors of metadata corresponding to the constraining variables.
lung_meta <- dplyr::filter(otu_df, specimen %in% rownames(otu_lung)) %>%
  dplyr::select(-str_which(colnames(otu_df), "Otu"))
cage_cca <- cca(otu_lung_hel ~ lung_meta$cage)
anova(cage_cca)
```

# IV. Relative Abundance of Key Community Members  

## 4.1 Identifying enriched taxonomic groups  

### 4.1.1 LEfSe  

```{r}
# library(lefse)
```

### 4.1.2 mvabund  
We'll make use of our previous mvabund results and examine whether there are any significant OTUs.  

```{r mva_pvals}
# restructure, sort, filter to retrieve significant OTUs
otu_ven_sigpvals <- data.frame(OTU = colnames(otu_mva_results$uni.p), uni_p = otu_mva_results$uni.p[2,]) %>%
  filter(uni_p <= .05) %>%
  droplevels() %>%
  arrange(uni_p) 

# label OTUS
otu_ven_sigpvals$OTU <- fct_inorder(paste0(otu_good_taxonomy[levels(otu_ven_sigpvals$OTU), ]$Genus, " (", levels(otu_ven_sigpvals$OTU), ")"))
```

Here is an example of formating a dataframe (in this case containing pvalues) for display in a report.  

```{r kable_mva_pvals, fig.height = 8, fig.width = 8}
knitr::kable(otu_ven_sigpvals, caption = "Vendors, Significant OTUs (.05)", align = "l")
```

### 4.1.3 Random forest (mean decrease in accuracy)  
Note - this depends on whether we're using regression or classification. A generic variable importance plot is shown for one iteration of the model.

```{r randomForest, cache = TRUE}
# exclude Cage, select 42-Day Experiments
rf_df <- dplyr::filter(otu_df, tissue_type == "Lung") %>% 
  dplyr::select(vendor, str_which(colnames(otu_df), "Otu")) %>% 
  droplevels()
  
a <- Sys.time()
set.seed(3462)
rf_ven <- randomForest(vendor ~ ., data = rf_df, importance = TRUE)
b <- Sys.time()
b-a

varImpPlot(rf_ven, scale = FALSE)
```

In order to better gauge the robustness of these findings, let's run the random forest model 100 times (note: this took around 30 seconds on a powerful machine).

```{r many_rf, cache = TRUE}
a <- Sys.time()
nforest <- 100
set.seed(3462)
rf_list <- vector("list", nforest)
for (i in seq_along(1:nforest)) {
    rf_list[[i]] <- randomForest(vendor ~ ., data = rf_df, importance = TRUE)
}
b <- Sys.time()
b-a

# Extract the feature importances
fi_df <- purrr::map(rf_list, ~{.[["importance"]][, 3]}) %>%
  unlist() %>%
  data.frame(Feature = names(.), MeanDecreaseAccuracy = .)

meas <- colnames(fi_df)[2] # "MeanDecreaseAccuracy"

# Identify the top features
top_feat <- fi_df %>% dplyr::group_by(Feature) %>%
  summarize(`:=`(!!meas, mean(.data[[meas]]))) %>%
  arrange(desc(.data[[meas]])) %>% 
        head(25) %>%
  droplevels()

# Retain only the top features
fi_df <- dplyr::filter(fi_df, Feature %in% top_feat$Feature) %>% 
        droplevels()
fi_df$Feature <- forcats::fct_reorder(fi_df$Feature, fi_df[, 2], .fun = mean, .desc = TRUE)
levels(fi_df$Feature) <- fct_inorder(paste0(otu_good_taxonomy[levels(fi_df$Feature), ]$Genus, " (", levels(fi_df$Feature), ")"))
```

Next we'll create boxplots of the feature importance over the 100 random forest runs.

```{r rf_feature_importance, fig.height=10, fig.width=8}
ggplot(fi_df, aes(x = Feature, y = fi_df[, 2])) + geom_boxplot(outlier.alpha = 0.4) + 
  theme_bw() + 
  labs(y = meas, title = paste0("Feature Importance: vendor ~ microbiome"), subtitle = paste0("Model: rf_df \nRuns: ", length(rf_list), ", mtry: ", rf_list[[1]]$mtry)) + 
  coord_flip() + 
  scale_x_discrete(limits = rev(levels(fi_df$Feature)))
```

# V. Community Diversity

## 5.1 Î±-diversity: within specimens

### Richness - how many unique taxa?
### Evenness - how evenly distributed?

Relative abundance plots can be used here

## 5.2 ð›½-diversity - across specimens  

### Bray-Curtis

### Unifrac

# VI. Knitting  
If all goes well, we should be able to create a report from the narrative and code. Click the Knit button in the top of RStudio to generate the default report type, which is set to html for this document.

# VII. Additional Resources  
Resources for learning more about various topics.  

## 7.1 Mothur/QIIME  
[mothur](https://mothur.org/)  

## 7.2 R  
[R for Data Science](https://r4ds.had.co.nz/)  
[RMarkdown tutorial](https://rmarkdown.rstudio.com/lesson-1.html)  
[tidyverse](https://www.tidyverse.org/packages/)  
[Ggplot2](https://ggplot2.tidyverse.org/)  
    - Includes several reference guides and learning sources  

## 7.3 Version control  
Git/github  

## 7.4 cbmbtools/course material  
Functions for assisting in 16S microbiome analysis  

## 7.5 other  
[Bioconductor](https://www.bioconductor.org/)  

```{r analyze_ae, include = FALSE}
# III. Analysis of Controls
# [Descriptive text here]

# 8 samples - perhaps ideal for use as an example of a control RA plot
# don't include geometric mean
# ae_df <- filter(otu_df, Specimen_ctrl == "AE")
# 
# # determine order of OTUs based on mean within selected specimens
# otu_order <- names(sort(colMeans(ae_df[, stringr::str_detect(colnames(ae_df), "Otu")]), decreasing = TRUE))
# 
# # create mean sample
# sample_names <- ae_df$Sample_name
# temp <- dplyr::select(ae_df, otu_order[1:20])
# temp <- rbind(temp, apply(dplyr::select(ae_df, otu_order[1:20]), 2, mean))
# sample_names <- append(sample_names, "Arith_Mean")
# ae_df <- cbind(Sample_name = forcats::fct_inorder(sample_names), temp)
# ae_gg <- tidyr::gather(ae_df, key = OTU, value = Percentage, -stringr::str_which(colnames(ae_df), "Otu", negate = TRUE), factor_key = TRUE)
# levels(ae_gg$OTU) <- forcats::fct_inorder(paste0(otu_good_taxonomy[levels(ae_gg$OTU), ]$Genus, " (", levels(ae_gg$OTU), ")"))
```

```{r plot_ae, fig.width = 12, fig.height = 12, include = FALSE}
# Encourage participants to run these by commenting out a layer, altering 1 parameter to develop a deeper understanding of how to build up a ggplot object

# ggplot(data = ae_gg, aes(x = OTU, y = Percentage, fill = Sample_name)) + 
#   geom_col() + 
#   facet_grid(Sample_name ~ .) +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5), legend.position = "top") +
#   scale_y_continuous(labels = scales::dollar_format(suffix = "%", prefix = "")) +
#   labs(title = "Cross-Comparison of AE Control Replicates", x = "OTU", y = "% Relative Abundance")
```
